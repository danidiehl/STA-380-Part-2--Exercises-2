---
title: "PM Assignment 2"
author: "Jess Chung"
date: "August 12, 2017"
output: html_document
---

## Question 1: Flights at ABIA

```{r}
library(dplyr)
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)
library(tidyr)

abia <- read.csv("C:/users/jessc/documents/predictivemodeling/abia.csv")
abia$Turnaround <- abia$ArrDelay - abia$DepDelay
abia[is.na(abia)] <- 0
abiaorigin <- filter(abia, Origin =="AUS")
abiaorigin <- abiaorigin[(abiaorigin$Dest != "DSM")&(abiaorigin$Dest != "DTW"),]

#abiadest <- filter(abia, Dest =="AUS")
airports <- read.csv("https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat", header = FALSE)
colnames(airports) <- c("ID", "name", "city", "country", "IATA_FAA", "ICAO", "lat", "lon", "altitude", "timezone", "DST")


airportlatlon <- subset(airports, select = c(IATA_FAA, lat, lon))

abiaorigin = merge(abiaorigin, airportlatlon, by.x = "Dest", by.y = "IATA_FAA")
#abiadest = merge(abiadest, airportlatlon, by.x = "Origin", by.y = "IATA_FAA")
origindata = abiaorigin[,c("lat","lon","Turnaround","Month")]
average = aggregate(origindata[, 3], list(origindata$lat, origindata$lon), mean)
origindataturnaround = merge(origindata, average, by.x = c("lat","lon"), by.y = c("Group.1","Group.2"))

abialatlon <- filter(airportlatlon, IATA_FAA=="AUS") #separate df for abia

usa <- map_data("usa")
origin <- gather(data = origindataturnaround, -lon, -lat, -x, -Turnaround, key = "var", value = "value")
ggplot() + geom_polygon(data = usa, aes(x=long, y = lat, group = group)) + coord_fixed(1.3) + 
geom_curve(data=origin, aes(x = lon, y = lat, xend = abialatlon$lon, yend = abialatlon$lat, col = x), size = .01, curvature = .2) + 
 geom_point(data=origin, aes(x = lon, y = lat), col = "red", shape = ".") + scale_colour_gradient2()# + facet_wrap(~value, scales = "free")
#What this is showing us is average turnaround time for flights departing from AUS. Redder curves have a slower turnaround time at AUS, purple-er times have a faster turnaround time. Ie, the flights to PHL had a super slow turnaround time, while the flights to SEA,MSP,CLT on average have a faster turnaround time.


```

##Question 2

```{r}

library(tm) 
library(magrittr)


readerPlain = function(fname){
				readPlain(elem=list(content=readLines(fname)), 
							id=fname, language='en') }

#Also, be sure to change the name of Lynne O'Donnell to remove the apostrophe
pathname = "C:/users/jessc/documents/STA-380-Part-2--Exercises-2/data/ReutersC50/"
train = paste(pathname,"C50train/", sep="")
test =paste(pathname,"C50test/", sep="")
authors = list.dirs(train, full.names = FALSE)[-1]
list_dtms_strings = c()
#For each author, create a corpus/document term matrix with removed sparse terms
for(author in authors){
  nam <- paste("articles_", author, sep = "")
  file = paste(train,author,"/*.txt",sep="")
  assign(nam, Sys.glob(file))
  assign(author, lapply(eval(parse(text = nam)),readerPlain))
  nam2 <- paste("names_", author, sep="")
  assign(nam2, eval(parse(text = nam)) %>%
	{ strsplit(., '/', fixed=TRUE) } %>%
	{ lapply(., tail, n=2) } %>%
	{ lapply(., paste0, collapse = '') } %>%
	unlist)
  assign(author,setNames(as.list(eval(parse(text = author))), eval(parse(text = nam2))))
  docs <- paste(author,"_documents", sep="")
  assign(docs, Corpus(VectorSource(eval(parse(text = author)))))
  assign(docs, tm_map(eval(parse(text = docs)), content_transformer(tolower)))
  assign(docs, tm_map(eval(parse(text = docs)), content_transformer(removeNumbers)))
  assign(docs, tm_map(eval(parse(text = docs)), content_transformer(removePunctuation)))
  assign(docs, tm_map(eval(parse(text = docs)), content_transformer(stripWhitespace)))
  assign(docs, tm_map(eval(parse(text = docs)), content_transformer(removeWords), c(stopwords("SMART"),"character")))
  dtm <- paste("dtm_",author,sep="")
  assign(dtm, TermDocumentMatrix(eval(parse(text=docs)), control = list(wordLengths = c(3,10))))
  assign(dtm, removeSparseTerms(eval(parse(text=dtm)),0.95))
  list_dtms_strings <-  append(list_dtms_strings, dtm)
    }
#

list_dtms1 <- lapply(1:length(list_dtms_strings), function(x) eval(parse(text=list_dtms_strings[x])))
top_words1 <- lapply(1:length(list_dtms1), function(x)  sort(rowSums(as.matrix(list_dtms1[[x]])), decreasing=TRUE))

library(plyr)
top_words_df <- t(ldply(1:length(top_words1), function(i)  head(names(top_words1[[i]]),20)))
colnames(top_words_df) <- lapply(1:length(list_dtms1), function(i) list_dtms_strings[i])

#Returns top 20 words for each author
top_words_df


```
